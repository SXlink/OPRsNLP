{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn as nn\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Загружаем данные\n",
    "df = pd.read_excel(r\"results\\treaning.xlsx\")\n",
    "\n",
    "text_col = \"text\"\n",
    "# Предполагаем, что столбцы для меток должны быть числовыми\n",
    "category_cols = [col for col in df.columns if col != text_col]\n",
    "df[category_cols] = df[category_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "df[\"labels\"] = df[category_cols].values.tolist()\n",
    "df.dropna(subset=[text_col], inplace=True)\n",
    "\n",
    "# Преобразуем в Dataset\n",
    "data = Dataset.from_pandas(df)\n",
    "train_dataset, test_dataset = data.train_test_split(test_size=0.2).values()\n",
    "\n",
    "# Устанавливаем max_length\n",
    "max_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruRoberta-large\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[text_col],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length\n",
    "    )\n",
    "    float_labels = []\n",
    "    for row in examples[\"labels\"]:\n",
    "        float_labels.append([float(x) for x in row])\n",
    "    tokenized[\"labels\"] = float_labels\n",
    "    return tokenized\n",
    "\n",
    "cols_to_remove = [text_col] + category_cols + [\"__index_level_0__\"]\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    remove_columns=cols_to_remove\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    remove_columns=cols_to_remove\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "num_labels = len(category_cols)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"ai-forever/ruRoberta-large\",\n",
    "    num_labels=num_labels,\n",
    "    problem_type='multi_label_classification'\n",
    ").cuda()\n",
    "\n",
    "# Вычисляем веса для функции потерь с учётом дисбаланса классов\n",
    "all_labels_train = np.array(train_dataset[\"labels\"])\n",
    "positive_counts = all_labels_train.sum(axis=0)\n",
    "negative_counts = all_labels_train.shape[0] - positive_counts\n",
    "eps = 1e-5\n",
    "pos_weight = (negative_counts + eps) / (positive_counts + eps)\n",
    "pos_weight = torch.tensor(pos_weight, dtype=torch.float32).cuda()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "def evaluate_model(model, dataloader, thresholds=None):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch).logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        if thresholds is None:\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "        else:\n",
    "            preds = np.zeros_like(probs)\n",
    "            for i, t in enumerate(thresholds):\n",
    "                preds[:, i] = (probs[:, i] > t).astype(int)\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    exact_match = np.mean(np.all(all_preds == all_labels, axis=1))\n",
    "    f1 = f1_score(all_labels, all_preds, average='samples')\n",
    "    return exact_match, f1\n",
    "\n",
    "def calibrate_thresholds(model, dataloader):\n",
    "    model.eval()\n",
    "    all_logits, all_labels = [], []\n",
    "    for batch in tqdm(dataloader, desc=\"Calibrating thresholds\"):\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch).logits\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "        all_labels.extend(labels)\n",
    "    all_logits = np.array(all_logits)\n",
    "    all_labels = np.array(all_labels)\n",
    "    optimal_thresholds = []\n",
    "    num_labels = all_labels.shape[1]\n",
    "    for i in range(num_labels):\n",
    "        best_threshold = 0.5\n",
    "        best_f1 = 0\n",
    "        for threshold in np.arange(0.1, 0.9, 0.05):\n",
    "            probs = 1 / (1 + np.exp(-all_logits[:, i]))\n",
    "            preds = (probs > threshold).astype(int)\n",
    "            f1 = f1_score(all_labels[:, i], preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        optimal_thresholds.append(best_threshold)\n",
    "    return optimal_thresholds\n",
    "\n",
    "# Гиперпараметры обучения\n",
    "num_epochs = 10  # увеличено число эпох\n",
    "gradient_accumulation_steps = 1\n",
    "cleanup_step = 100\n",
    "report_step = 50\n",
    "ewm_loss = 0\n",
    "window = 500\n",
    "\n",
    "# Настраиваем оптимизатор и scheduler\n",
    "learning_rate = 2e-5  # можно варьировать\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1*total_steps), num_training_steps=total_steps)\n",
    "\n",
    "# Ранняя остановка: если F1 на валидации не улучшается в течение patience эпох, останавливаем обучение\n",
    "patience = 3\n",
    "best_f1 = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# На первом этапе можно заморозить базовые слои, а затем разморозить их\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "    # Если это не первый эпоh, размораживаем базовые слои\n",
    "    if epoch > 0:\n",
    "        for param in model.roberta.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    model.train()\n",
    "    cleanup()\n",
    "    tq = tqdm(train_dataloader, desc=\"Training\")\n",
    "    for i, batch in enumerate(tq):\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "        batch['labels'] = batch['labels'].float()  # преобразуем метки в float\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, batch['labels'])\n",
    "        loss.backward()\n",
    "        \n",
    "        if (i + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # обновляем lr\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        if i % cleanup_step == 0:\n",
    "            cleanup()\n",
    "        \n",
    "        w = 1 / min(i + 1, window)\n",
    "        ewm_loss = ewm_loss * (1 - w) + loss.item() * w\n",
    "        tq.set_description(f'loss: {ewm_loss:.4f}')\n",
    "        \n",
    "        if i % report_step == 0 and i > 0:\n",
    "            eval_acc, eval_f1 = evaluate_model(model, test_dataloader)\n",
    "            print(f'epoch {epoch}, step {i}: train loss: {ewm_loss:.4f}, exact match acc: {eval_acc:.4f}, F1: {eval_f1:.4f}')\n",
    "    \n",
    "    # Оценка модели после каждой эпохи\n",
    "    eval_acc, eval_f1 = evaluate_model(model, test_dataloader)\n",
    "    print(f'Epoch {epoch} завершена: exact match acc: {eval_acc:.4f}, F1: {eval_f1:.4f}')\n",
    "    \n",
    "    # Ранняя остановка: если улучшение F1 отсутствует, увеличиваем счётчик\n",
    "    if eval_f1 > best_f1:\n",
    "        best_f1 = eval_f1\n",
    "        epochs_without_improvement = 0\n",
    "        # Сохраняем лучшую модель\n",
    "        model.save_pretrained(\"./best_ruRoberta_multilabel_model\")\n",
    "        tokenizer.save_pretrained(\"./best_ruRoberta_multilabel_model\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Улучшение F1 не наблюдалось в течение {epochs_without_improvement} эпох.\")\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Ранняя остановка обучения.\")\n",
    "            break\n",
    "\n",
    "optimal_thresholds = calibrate_thresholds(model, test_dataloader)\n",
    "print(\"Optimal thresholds for each category:\", optimal_thresholds)\n",
    "\n",
    "model.eval()\n",
    "model.save_pretrained(\"./final_ruRoberta_multilabel_model\")\n",
    "tokenizer.save_pretrained(\"./final_ruRoberta_multilabel_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем устройство: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Классификация отзывов: 100%|██████████| 75/75 [00:27<00:00,  2.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классификация завершена. Результаты записаны в файл: classified_reviews_prodoctorov.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 1. Считываем отзывы из Excel-файла\n",
    "input_file = r\"results\\reviews.xlsx\"  # Название входного файла Excel\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Если колонки \"Классификация\" ещё нет, добавляем её; если есть, заполняем пустыми значениями\n",
    "if \"Классификация\" not in df.columns:\n",
    "    df[\"Классификация\"] = \"\"\n",
    "else:\n",
    "    df[\"Классификация\"] = df[\"Классификация\"].fillna(\"\")\n",
    "\n",
    "# Определяем индексы отзывов, у которых ещё нет классификации (пустое значение в колонке \"Классификация\")\n",
    "pending_indices = df.index[df[\"Классификация\"] == \"\"].tolist()\n",
    "pending_reviews = df.loc[pending_indices, \"Отзыв\"].tolist()\n",
    "\n",
    "# 2. Список категорий (используется лишь для определения порядка меток)\n",
    "label_names = [\n",
    "    \"Материальный аспект (позитивный)\",\n",
    "    \"Материальный аспект (негативный)\",\n",
    "    \"Аспект безопасности (позитивный)\",\n",
    "    \"Аспект безопасности (негативный)\",\n",
    "    \"Аспект эффективности (позитивный)\",\n",
    "    \"Аспект эффективности (негативный)\",\n",
    "    \"Межличностный аспект (позитивный)\",\n",
    "    \"Межличностный аспект (негативный)\"\n",
    "]\n",
    "\n",
    "# 3. Определяем устройство: cuda, если доступна, иначе cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Используем устройство:\", device)\n",
    "\n",
    "# 4. Загрузка модели и токенизатора для Roberta и перемещение модели на устройство\n",
    "model_path = \"./final_ruRoberta_multilabel_model\"  # Убедитесь, что здесь находится модель на основе Roberta\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Порог для определения активности метки\n",
    "threshold = 0.7\n",
    "\n",
    "# 5. Обработка отзывов, у которых отсутствует классификация, пакетами с отображением ETA\n",
    "batch_size = 16  # Размер батча можно регулировать\n",
    "n_pending = len(pending_reviews)\n",
    "start_overall = time.time()\n",
    "\n",
    "for i in tqdm(range(0, n_pending, batch_size), desc=\"Классификация отзывов\", unit=\"batch\"):\n",
    "    batch_reviews = pending_reviews[i: i + batch_size]\n",
    "    \n",
    "    # Токенизация отзывов с переносом на устройство\n",
    "    inputs = tokenizer(\n",
    "        batch_reviews,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Получаем бинарные предсказания для каждой метки\n",
    "    predictions = (torch.sigmoid(logits) > threshold).int().cpu().numpy()\n",
    "    \n",
    "    # Обновляем DataFrame для каждой обработанной записи, записывая строку из 8 цифр через запятую\n",
    "    for j, pred in enumerate(predictions):\n",
    "        pred_str = \",\".join(map(str, pred.tolist()))\n",
    "        orig_idx = pending_indices[i + j]\n",
    "        df.at[orig_idx, \"Классификация\"] = pred_str\n",
    "    \n",
    "    # Расчет оставшегося времени (ETA)\n",
    "    processed = min(i + batch_size, n_pending)\n",
    "    elapsed = time.time() - start_overall\n",
    "    avg_time = elapsed / processed if processed > 0 else 0\n",
    "    remaining_reviews = n_pending - processed\n",
    "    remaining_time = remaining_reviews * avg_time\n",
    "\n",
    "\n",
    "# 6. Сохраняем обновленный DataFrame в новый Excel-файл\n",
    "output_file = \"classified_reviews_prodoctorov.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(\"Классификация завершена. Результаты записаны в файл:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем устройство: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Анализ эмоций: 100%|██████████| 77/77 [00:12<00:00,  5.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ эмоций завершён. Результаты записаны в файл: classified_reviews_prodoctorov.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 1. Считываем отзывы из Excel-файла\n",
    "input_file = r\"results\\reviews.xlsx\"  # Файл с отзывами. Предполагается, что текст отзыва находится в колонке \"Отзыв\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# Если колонки \"Эмоции\" ещё нет, создаём её; если есть – заполняем NaN пустыми строками\n",
    "if \"Эмоции\" not in df.columns:\n",
    "    df[\"Эмоции\"] = \"\"\n",
    "else:\n",
    "    df[\"Эмоции\"] = df[\"Эмоции\"].fillna(\"\")\n",
    "\n",
    "# Определяем индексы отзывов, для которых ещё не выполнен анализ эмоций\n",
    "pending_indices = df.index[df[\"Эмоции\"] == \"\"].tolist()\n",
    "pending_reviews = df.loc[pending_indices, \"Отзыв\"].tolist()\n",
    "\n",
    "# 2. Параметры модели эмоций\n",
    "best_thresholds = [0.36734693877551017, 0.2857142857142857, 0.2857142857142857, 0.16326530612244897, \n",
    "                   0.14285714285714285, 0.14285714285714285, 0.18367346938775508, 0.3469387755102041, \n",
    "                   0.32653061224489793, 0.22448979591836732, 0.2040816326530612, 0.2857142857142857, \n",
    "                   0.18367346938775508, 0.2857142857142857, 0.24489795918367346, 0.7142857142857142, \n",
    "                   0.02040816326530612, 0.3061224489795918, 0.44897959183673464, 0.061224489795918366, \n",
    "                   0.18367346938775508, 0.04081632653061224, 0.08163265306122448, 0.1020408163265306, \n",
    "                   0.22448979591836732, 0.3877551020408163, 0.3469387755102041, 0.24489795918367346]\n",
    "\n",
    "LABELS = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', \n",
    "          'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', \n",
    "          'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', \n",
    "          'remorse', 'sadness', 'surprise', 'neutral']\n",
    "ID2LABEL = dict(enumerate(LABELS))\n",
    "\n",
    "# 3. Определяем устройство: если доступна CUDA, используем GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Используем устройство:\", device)\n",
    "\n",
    "# Загрузка токенизатора и модели для анализа эмоций\n",
    "model_name = \"fyaronskiy/ruRoberta-large-ru-go-emotions\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Приводим best_thresholds к тензору и перемещаем на устройство\n",
    "best_thresholds_tensor = torch.tensor(best_thresholds).to(device)\n",
    "\n",
    "# 4. Обработка отзывов пакетами с отображением оставшегося времени (ETA)\n",
    "batch_size = 16  # Можно скорректировать размер батча\n",
    "n_pending = len(pending_reviews)\n",
    "start_overall = time.time()\n",
    "\n",
    "for i in tqdm(range(0, n_pending, batch_size), desc=\"Анализ эмоций\", unit=\"batch\"):\n",
    "    batch_reviews = pending_reviews[i: i + batch_size]\n",
    "    \n",
    "    # Токенизируем отзывы (для каждого батча)\n",
    "    inputs = tokenizer(\n",
    "        batch_reviews,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits  # shape: (batch_size, 28)\n",
    "\n",
    "    # Вычисляем вероятность для каждой эмоции (сигмоида)\n",
    "    probas = torch.sigmoid(logits)  # на устройстве, shape: (batch_size, 28)\n",
    "    # Применяем порог для получения бинарных меток по каждому классу\n",
    "    predictions = (probas > best_thresholds_tensor).int().cpu().numpy()  # возвращаем результат в CPU\n",
    "\n",
    "    # Обновляем DataFrame: формируем для каждого отзыва строку с предсказанными эмоциями\n",
    "    for j, pred in enumerate(predictions):\n",
    "        emotions = [ID2LABEL[label_id] for label_id, value in enumerate(pred) if value == 1]\n",
    "        # Если ни одна эмоция не предсказана – можно записать, например, \"neutral\" или пустую строку.\n",
    "        emotions_str = \", \".join(emotions) if emotions else \"\"\n",
    "        orig_idx = pending_indices[i + j]\n",
    "        df.at[orig_idx, \"Эмоции\"] = emotions_str\n",
    "\n",
    "    # Вычисление оставшегося времени (ETA)\n",
    "    processed = min(i + batch_size, n_pending)\n",
    "    elapsed = time.time() - start_overall\n",
    "    avg_time = elapsed / processed if processed > 0 else 0\n",
    "    remaining_reviews = n_pending - processed\n",
    "    remaining_time = remaining_reviews * avg_time\n",
    "\n",
    "\n",
    "# 5. Сохраняем обновленный DataFrame в новый Excel-файл\n",
    "output_file = \"classified_reviews_prodoctorov.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(\"Анализ эмоций завершён. Результаты записаны в файл:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  web-scraper-order                                              Отзыв  score  \\\n",
      "0      1746816383-1  Операция была 19 сентября 2017 года. Оперирова...    5.0   \n",
      "1      1746816383-2  Выражаю глубокие слова благодарности медицинск...    5.0   \n",
      "2      1746816383-3  Новокшонову Константину Юрьевичу. Большое спас...    5.0   \n",
      "3      1746816383-4  Я, Лифшиц Нина Аркадьевна, 89 лет, Санкт-Петер...    5.0   \n",
      "4      1746816383-5  15.08.2017 моей жене была проведена операция п...    5.0   \n",
      "\n",
      "                                      date    Классификация  \\\n",
      "0  27 сентября 2017\\n\\n            в 17:32  1,0,1,0,1,0,1,0   \n",
      "1  22 сентября 2017\\n\\n            в 22:37  1,0,1,0,1,0,1,0   \n",
      "2  19 сентября 2017\\n\\n            в 18:33  0,0,0,0,1,0,1,0   \n",
      "3  11 сентября 2017\\n\\n            в 13:31  0,0,1,0,1,0,1,0   \n",
      "4  11 сентября 2017\\n\\n            в 10:14  0,0,1,0,1,0,1,0   \n",
      "\n",
      "   Материальный аспект (позитивный)  Материальный аспект (негативный)  \\\n",
      "0                                 1                                 0   \n",
      "1                                 1                                 0   \n",
      "2                                 0                                 0   \n",
      "3                                 0                                 0   \n",
      "4                                 0                                 0   \n",
      "\n",
      "   Аспект безопасности (позитивный)  Аспект безопасности (негативный)  \\\n",
      "0                                 1                                 0   \n",
      "1                                 1                                 0   \n",
      "2                                 0                                 0   \n",
      "3                                 1                                 0   \n",
      "4                                 1                                 0   \n",
      "\n",
      "   Аспект эффективности (позитивный)  Аспект эффективности (негативный)  \\\n",
      "0                                  1                                  0   \n",
      "1                                  1                                  0   \n",
      "2                                  1                                  0   \n",
      "3                                  1                                  0   \n",
      "4                                  1                                  0   \n",
      "\n",
      "   Межличностный аспект (позитивный)  Межличностный аспект (негативный)  \\\n",
      "0                                  1                                  0   \n",
      "1                                  1                                  0   \n",
      "2                                  1                                  0   \n",
      "3                                  1                                  0   \n",
      "4                                  1                                  0   \n",
      "\n",
      "                  Эмоции  Положительные_эмоции  Отрицательные_эмоции  Оценка  \n",
      "0  admiration, gratitude                     1                     0     5.0  \n",
      "1              gratitude                     1                     0     5.0  \n",
      "2              gratitude                     1                     0     5.0  \n",
      "3  admiration, gratitude                     1                     0     5.0  \n",
      "4  admiration, gratitude                     1                     0     5.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Определяем множества положительных и отрицательных эмоций\n",
    "positive_emotions = {\n",
    "    'admiration', 'amusement', 'approval', 'caring',\n",
    "    'excitement', 'gratitude', 'joy', 'love',\n",
    "    'optimism', 'pride', 'relief'\n",
    "}\n",
    "negative_emotions = {\n",
    "    'anger', 'annoyance', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'fear', 'grief',\n",
    "    'nervousness', 'remorse', 'sadness'\n",
    "}\n",
    "\n",
    "# Загрузка Excel-файла (замените 'your_file.xlsx' на ваш файл)\n",
    "input_file = r\"results\\reviews.xlsx\"  # Файл с отзывами. Предполагается, что текст отзыва находится в колонке \"Отзыв\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "\n",
    "def classify_emotions(emotion_str):\n",
    "    \"\"\"\n",
    "    Функция разбивает строку эмоций (разделенных запятыми) \n",
    "    и возвращает кортеж (положительная_эмоция, отрицательная_эмоция).\n",
    "    \n",
    "    Если значение пустое или равно \"neutral\", возвращает (0, 0).\n",
    "    \"\"\"\n",
    "    # Если значение пустое или NaN\n",
    "    if pd.isna(emotion_str) or not str(emotion_str).strip():\n",
    "        return 0, 0\n",
    "\n",
    "    # Разбиваем строку по запятой и приводим к нижнему регистру\n",
    "    emotions = [e.strip().lower() for e in emotion_str.split(',')]\n",
    "    \n",
    "    # Если присутствует только значение \"neutral\"\n",
    "    if len(emotions) == 1 and emotions[0] == 'neutral':\n",
    "        return 0, 0\n",
    "    \n",
    "    # Проверяем, есть ли среди эмоций положительная и отрицательная\n",
    "    positive_flag = 1 if any(e in positive_emotions for e in emotions) else 0\n",
    "    negative_flag = 1 if any(e in negative_emotions for e in emotions) else 0\n",
    "\n",
    "    return positive_flag, negative_flag\n",
    "\n",
    "# Применяем функцию к колонке \"Эмоции\"\n",
    "df[['Положительные_эмоции', 'Отрицательные_эмоции']] = df['Эмоции'].apply(\n",
    "    lambda x: pd.Series(classify_emotions(x))\n",
    ")\n",
    "\n",
    "# Вывод первых строк полученного DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Сохраняем результат в новый Excel-файл (при необходимости)\n",
    "df.to_excel('Продокторов_полный.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список отзывов для классификации\n",
    "reviews = [\n",
    "    \"Впечатляет наличие современного оборудования и высоких технологий, которые помогли быстро поставить диагноз.\",\n",
    "    \"Долгие очереди и некомпетентный персонал оставили неприятное впечатление.\",\n",
    "    \"Прекрасный ремонт, чистота помещений и дружелюбный персонал – рекомендую!\",\n",
    "    \"Современная клиника и эффективное лечение, однако персонал удивил невниманием.\",\n",
    "]\n",
    "\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "# Прямой список названий категорий\n",
    "label_names = [\n",
    "    \"Материальный аспект (позитивный)\",\n",
    "    \"Материальный аспект (негативный)\",\n",
    "    \"Аспект безопасности (позитивный)\",\n",
    "    \"Аспект безопасности (негативный)\",\n",
    "    \"Аспект эффективности (позитивный)\",\n",
    "    \"Аспект эффективности (негативный)\",\n",
    "    \"Межличностный аспект (позитивный)\",\n",
    "    \"Межличностный аспект (негативный)\"\n",
    "]\n",
    "\n",
    "# Загрузка модели и токенизатора для Roberta\n",
    "model_path = \"./final_ruRoberta_multilabel_model\"  # Путь к модели. Убедитесь, что он соответствует модели, обученной на основе Roberta.\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Токенизация отзывов\n",
    "inputs = tokenizer(\n",
    "    reviews,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Порог для активации метки (можно экспериментировать, например, 0.4)\n",
    "threshold = 0.7\n",
    "\n",
    "# Прогнозирование\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Применяем сигмоиду и пороговое значение для получения бинарных меток\n",
    "predictions = (torch.sigmoid(logits) > threshold).int().cpu().numpy()\n",
    "print(predictions)\n",
    "\n",
    "# Выводим результат для каждого отзыва\n",
    "for review, pred in zip(reviews, predictions):\n",
    "    active_labels = [label for label, flag in zip(label_names, pred) if flag == 1]\n",
    "    print(\"Отзыв:\", review)\n",
    "    print(\"Предсказанные категории:\", active_labels if active_labels else \"Нет активных категорий\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
